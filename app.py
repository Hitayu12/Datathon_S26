"""SignalForge: Failure intelligence dashboard with survivor benchmarking and simulation."""

from __future__ import annotations

import json
import os
import html
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import altair as alt
import pandas as pd
import streamlit as st
from dotenv import load_dotenv

from data_loader import (
    fetch_company_info,
    fetch_company_profile,
    fetch_financials,
    find_peer_companies,
    resolve_company_input,
)
from financial_analysis import compute_metrics
from groq_client import GroqReasoningClient
from local_reasoner import LocalAnalystModel
from nlp_analysis import qualitative_summary
from risk_model import (
    LayeredAnalysisEngine,
    MultiFactorRiskEngine,
    compare_failure_vs_survivors,
    generate_strategy_recommendations,
    simulate_counterfactual,
)
from tavily_client import TavilyClient

load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), ".env"))


def _inject_styles() -> None:
    st.markdown(
        """
        <style>
        :root {
            --bg: #d3dced;
            --card: #edf2fb;
            --ink: #0f172a;
            --muted: #334155;
            --teal: #0ea5a6;
            --navy: #1d3557;
            --orange: #fb8500;
            --danger: #e63946;
            --line: #b8c6df;
        }
        .stApp {
            background: radial-gradient(circle at 10% 2%, #d6e0ef 0%, #c8d4e7 38%, #bccbdd 100%);
            color: var(--ink);
        }
        .block-container {
            padding-top: 1.05rem !important;
            max-width: 1220px !important;
        }
        .stApp, .stApp p, .stApp span, .stApp li, .stApp h1, .stApp h2, .stApp h3, .stApp h4 {
            color: var(--ink);
        }
        div[data-testid="stWidgetLabel"] p,
        div[data-testid="stWidgetLabel"] label,
        .stTextInput label,
        .stSlider label,
        .stSelectbox label,
        .stTextArea label {
            color: #0f172a !important;
            font-weight: 600 !important;
        }
        div[data-baseweb="input"],
        div[data-baseweb="base-input"] {
            background: #ffffff !important;
            border: 1px solid #cbd5e1 !important;
        }
        div[data-baseweb="input"] input,
        div[data-baseweb="base-input"] input {
            color: #0f172a !important;
            -webkit-text-fill-color: #0f172a !important;
            caret-color: #0f172a !important;
        }
        div[data-testid="stExpander"] {
            background: #ffffff !important;
            border: 1px solid var(--line) !important;
            border-radius: 10px !important;
        }
        div[data-testid="stExpander"] details summary {
            background: #f8fafc !important;
            border-radius: 10px !important;
        }
        div[data-testid="stExpander"] details summary p,
        div[data-testid="stExpander"] details summary span {
            color: #0f172a !important;
            font-weight: 600 !important;
        }
        div[data-baseweb="slider"] * {
            color: #0f172a !important;
        }
        .hero {
            background: linear-gradient(125deg, #11213f 0%, #1f3a63 46%, #0c8d98 100%);
            border-radius: 18px;
            color: #f8fbff;
            padding: 1.25rem 1.35rem;
            box-shadow: 0 16px 34px rgba(15, 23, 42, 0.22);
            margin-bottom: 1rem;
        }
        .hero h1 { margin: 0; font-size: 1.9rem; }
        .hero p { margin: 0.35rem 0 0; color: #e6fbff; }
        .step-grid { display:grid; grid-template-columns: repeat(3,minmax(120px,1fr)); gap:0.7rem; margin-top:0.9rem; }
        .step-item { background: rgba(255,255,255,0.16); border:1px solid rgba(255,255,255,0.30); border-radius:10px; padding:0.65rem; font-size:0.9rem; }
        .panel { background:var(--card); border:1px solid var(--line); border-radius:14px; padding:0.85rem; box-shadow:0 8px 20px rgba(13, 30, 58, 0.12); }
        .hint {
            border-bottom: 1px dotted #0b5d66;
            cursor: help;
            font-weight: 600;
        }
        .wow {
            background: linear-gradient(120deg, rgba(29,53,87,.12), rgba(14,165,166,.12));
            border: 1px solid #9bb7d9;
            border-radius: 12px;
            padding: 0.7rem 0.8rem;
        }
        .badge {
            display:inline-block; border-radius:999px; font-size:0.8rem; font-weight:700; padding:0.28rem 0.65rem;
            border:1px solid;
        }
        .badge-ok { background:#dcfce7; color:#166534; border-color:#bbf7d0; }
        .badge-failed { background:#fee2e2; color:#b91c1c; border-color:#fecaca; }
        .explain { background:#eaf1fb; border:1px solid var(--line); border-left:5px solid var(--teal); border-radius:14px; padding:0.9rem; }

        div[data-testid="stMetric"] {
            background:#f3f7ff;
            border:1px solid #c2d0e5;
            border-radius:12px;
            padding:0.5rem 0.7rem;
            box-shadow:0 6px 16px rgba(20,33,61,0.08);
        }
        div[data-testid="stMetricLabel"] p {
            color:#6b7280 !important;
            font-weight:600 !important;
        }
        div[data-testid="stMetricValue"] {
            color:#0f172a !important;
            font-weight:700 !important;
        }
        .stTabs [data-baseweb="tab-list"] {
            gap: 0.5rem;
        }
        .stTabs [data-baseweb="tab"] {
            background: #ecf3ff;
            border: 1px solid #cddcf5;
            border-radius: 10px;
            color: #17355e;
            font-weight: 600;
            padding: 0.45rem 0.8rem;
        }
        .stTabs [aria-selected="true"] {
            background: #1d3557 !important;
            color: #ffffff !important;
            border-color: #1d3557 !important;
        }
        .stButton > button,
        div[data-testid="stDownloadButton"] > button,
        button[kind="secondary"],
        button[kind="primary"] {
            background: linear-gradient(120deg, #163660 0%, #0d8f99 100%);
            color: white;
            border: 1px solid #0d6f79;
            border-radius: 10px;
            font-weight: 700;
            box-shadow: 0 6px 14px rgba(20, 33, 61, 0.23);
            opacity: 1 !important;
        }
        .stButton > button:hover,
        div[data-testid="stDownloadButton"] > button:hover,
        button[kind="secondary"]:hover,
        button[kind="primary"]:hover {
            filter: brightness(1.08);
            border-color: #0ea5a6;
        }
        .stButton > button span,
        div[data-testid="stDownloadButton"] > button span {
            color: #ffffff !important;
            font-weight: 700 !important;
        }
        div[data-testid="stDownloadButton"] {
            width: 100%;
        }
        div[data-testid="stDownloadButton"] > button {
            width: 100%;
        }
        .stTabs [data-baseweb="tab"] p,
        .stTabs [data-baseweb="tab"] span {
            color: inherit !important;
        }
        .stVegaLiteChart text,
        .vega-embed text {
            fill: #0f172a !important;
            color: #0f172a !important;
            font-weight: 600 !important;
        }
        .stVegaLiteChart .role-axis-label text,
        .stVegaLiteChart .role-legend text {
            fill: #0f172a !important;
        }
        .st-key-jarvis_trigger {
            position: fixed;
            right: 18px;
            bottom: 18px;
            width: 148px;
            z-index: 10001;
        }
        .st-key-jarvis_trigger > div {
            background: transparent !important;
            border: none !important;
            box-shadow: none !important;
            padding: 0 !important;
        }
        .st-key-jarvis_trigger .stButton > button {
            height: 48px;
            border-radius: 999px !important;
            padding: 0.45rem 0.82rem !important;
            font-size: 0.84rem !important;
            font-weight: 700 !important;
            white-space: nowrap;
            background: linear-gradient(120deg, #18c4ad 0%, #25b5ca 100%) !important;
            border: 1px solid #75d7cd !important;
            color: #032a2f !important;
            box-shadow: 0 10px 20px rgba(10, 75, 95, 0.42) !important;
        }
        .st-key-jarvis_panel {
            position: fixed;
            right: 18px;
            bottom: 84px;
            width: min(360px, 92vw);
            max-height: min(64vh, 540px);
            z-index: 10000;
            background: radial-gradient(circle at 8% 6%, #0b1f45 0%, #061833 44%, #020f26 100%);
            border: 1px solid rgba(101, 163, 255, 0.3);
            border-radius: 20px;
            box-shadow: 0 20px 52px rgba(2, 6, 23, 0.58);
            padding: 0.9rem;
            backdrop-filter: blur(8px);
            overflow-x: hidden;
            overflow-y: auto;
        }
        .st-key-jarvis_panel p,
        .st-key-jarvis_panel label,
        .st-key-jarvis_panel span,
        .st-key-jarvis_panel h1,
        .st-key-jarvis_panel h2,
        .st-key-jarvis_panel h3 {
            color: #dbeafe !important;
        }
        .st-key-jarvis_panel div[data-baseweb="input"],
        .st-key-jarvis_panel div[data-baseweb="base-input"] {
            background: rgba(10, 20, 38, 0.92) !important;
            border: 1px solid #32496e !important;
            border-radius: 999px !important;
            min-height: 44px !important;
        }
        .st-key-jarvis_panel div[data-baseweb="input"] input,
        .st-key-jarvis_panel div[data-baseweb="base-input"] input {
            color: #e2e8f0 !important;
            -webkit-text-fill-color: #e2e8f0 !important;
            padding: 0.52rem 0.86rem !important;
            font-size: 0.97rem !important;
            line-height: 1.2 !important;
        }
        .st-key-jarvis_panel div[data-testid="InputInstructions"] {
            display: none !important;
        }
        .st-key-jarvis_panel form {
            border: none !important;
            padding: 0 !important;
            margin: 0 !important;
            background: transparent !important;
        }
        .st-key-jarvis_panel .stButton > button {
            border-radius: 999px !important;
            white-space: nowrap !important;
            font-size: 0.95rem !important;
            min-height: 44px !important;
            padding: 0.4rem 0.9rem !important;
            width: 100% !important;
            line-height: 1.1 !important;
        }
        .st-key-jarvis_panel button[kind="secondary"] {
            background: #0a1a34 !important;
            border: 1px solid #3c5174 !important;
            color: #e5e7eb !important;
            box-shadow: none !important;
        }
        .st-key-jarvis_panel button[kind="primary"] {
            background: linear-gradient(120deg, #20c9b1, #29b8d1) !important;
            border: 1px solid #77e0d8 !important;
            color: #062a33 !important;
            box-shadow: none !important;
        }
        .jarvis-title { color:#f8fafc !important; font-size:1.45rem; font-weight:700; line-height:1; margin-bottom:.15rem; }
        .jarvis-sub { color:#a6bddf !important; font-size:.8rem; margin-bottom:.2rem; }
        @media (max-width: 640px) {
            .st-key-jarvis_panel {
                right: 10px;
                bottom: 74px;
                width: calc(100vw - 20px);
                max-height: 60vh;
                border-radius: 16px;
            }
            .st-key-jarvis_trigger {
                right: 10px;
                bottom: 10px;
            }
            .jarvis-title {
                font-size: 1.3rem;
            }
        }
        </style>
        """,
        unsafe_allow_html=True,
    )


def _render_header() -> None:
    st.markdown(
        """
        <div class="hero">
          <h1>SignalForge Failure Intelligence</h1>
          <p>Enter a company name or ticker. We verify failure, compare survivors, and show what would have prevented collapse.</p>
          <div class="step-grid">
            <div class="step-item"><b>1) Verify Failure</b><br/>Checks if the case is truly failed/distressed.</div>
            <div class="step-item"><b>2) Benchmark Survivors</b><br/>Finds peers that survived similar stress.</div>
            <div class="step-item"><b>3) Simulate Prevention</b><br/>Recomputes risk if survivor moves were applied.</div>
          </div>
        </div>
        """,
        unsafe_allow_html=True,
    )


def _fmt_num(value: object) -> str:
    if value is None:
        return "N/A"
    try:
        n = float(value)
    except (TypeError, ValueError):
        return str(value)
    if abs(n) >= 1_000_000_000:
        return f"{n/1_000_000_000:.2f}B"
    if abs(n) >= 1_000_000:
        return f"{n/1_000_000:.2f}M"
    if abs(n) >= 1_000:
        return f"{n/1_000:.2f}K"
    return f"{n:.3f}" if abs(n) < 10 else f"{n:.2f}"


def _friendly_metric_name(name: str) -> str:
    mapping = {
        "debt_to_equity": "Debt / Equity",
        "current_ratio": "Current Ratio",
        "cash_burn": "Cash Burn",
        "revenue_growth": "Revenue Growth",
        "expense_growth": "Expense Growth",
        "inventory_growth": "Inventory Growth",
        "gross_margin": "Gross Margin",
        "operating_margin": "Operating Margin",
        "total_debt": "Total Debt",
        "cash_and_equivalents": "Cash & Equivalents",
        "revenue": "Revenue",
        "operating_expense": "Operating Expense",
    }
    return mapping.get(name, name.replace("_", " ").title())


def _friendly_theme_name(name: str) -> str:
    mapping = {
        "liquidity_concerns": "Liquidity Concerns",
        "debt_stress": "Debt Stress",
        "demand_decline": "Demand Decline",
        "margin_pressure": "Margin Pressure",
        "legal_regulatory": "Legal / Regulatory",
        "bankruptcy_language": "Bankruptcy Language",
    }
    return mapping.get(name, name.replace("_", " ").title())


def _clean_metrics(metrics: Dict[str, object]) -> Dict[str, object]:
    out: Dict[str, object] = {}
    for k, v in metrics.items():
        if isinstance(v, (int, float)):
            out[k] = round(float(v), 6)
        else:
            out[k] = v
    return out


def _metrics_table(metrics: Dict[str, object], hide_missing: bool = False) -> pd.DataFrame:
    rows = []
    for k, v in metrics.items():
        if hide_missing and v is None:
            continue
        rows.append({"Metric": _friendly_metric_name(k), "Value": _fmt_num(v)})
    return pd.DataFrame(rows)


def _core_metric_quality(metrics: Dict[str, Optional[float]]) -> int:
    keys = ["debt_to_equity", "current_ratio", "cash_burn", "revenue_growth", "revenue"]
    return sum(1 for k in keys if metrics.get(k) is not None)


def _impute_failed_defaults(metrics: Dict[str, Optional[float]]) -> Tuple[Dict[str, Optional[float]], bool]:
    patched = dict(metrics)
    changed = False

    if patched.get("revenue") is None:
        patched["revenue"] = 1_000_000_000.0
        changed = True
    if patched.get("debt_to_equity") is None:
        patched["debt_to_equity"] = 3.1
        changed = True
    if patched.get("current_ratio") is None:
        patched["current_ratio"] = 0.72
        changed = True
    if patched.get("cash_burn") is None:
        patched["cash_burn"] = 240_000_000.0
        changed = True
    if patched.get("revenue_growth") is None:
        patched["revenue_growth"] = -0.16
        changed = True

    return patched, changed


def _impute_survivor_defaults(metrics: Dict[str, Optional[float]], ticker: str) -> Tuple[Dict[str, Optional[float]], bool]:
    patched = dict(metrics)
    changed = False
    seed = sum(ord(c) for c in ticker)

    if patched.get("revenue") is None:
        patched["revenue"] = float(10_000_000_000 + (seed % 18) * 1_500_000_000)
        changed = True
    if patched.get("debt_to_equity") is None:
        patched["debt_to_equity"] = round(0.8 + (seed % 12) / 20.0, 3)
        changed = True
    if patched.get("current_ratio") is None:
        patched["current_ratio"] = round(1.25 + (seed % 8) / 20.0, 3)
        changed = True
    if patched.get("cash_burn") is None:
        patched["cash_burn"] = 0.0
        changed = True
    if patched.get("revenue_growth") is None:
        patched["revenue_growth"] = round(0.03 + (seed % 6) / 100.0, 3)
        changed = True

    return patched, changed


def _fetch_tavily_intelligence(tavily_client: TavilyClient, company_name: str, ticker: str, industry: str) -> Dict[str, object]:
    if not tavily_client.enabled:
        return {
            "macro_stress_score": 50.0,
            "macro_notes": ["Macro intelligence unavailable (no Tavily key)."],
            "qual_snippets": [],
            "sources": [],
            "strategy_notes": [],
            "failure_check": {"answer": "", "snippets": [], "sources": []},
        }

    macro_query = f"Macro stress for {industry} with rates, credit, demand and default pressure"
    qual_query = f"{company_name} {ticker} liquidity risk covenant breach restructuring distress signals"
    strategy_query = f"Survivor strategies for stressed {industry} companies that avoided collapse"
    failure_query = f"Did {company_name} {ticker} fail: chapter 11 bankruptcy liquidation insolvency collapse"

    macro_result = tavily_client.search(macro_query, max_results=4)
    qual_result = tavily_client.search(qual_query, max_results=5)
    strategy_result = tavily_client.search(strategy_query, max_results=4)
    failure_result = tavily_client.search(failure_query, max_results=5)

    macro_text = " ".join([macro_result.answer, *macro_result.snippets]).lower()
    macro_score = 32.0
    keyword_impacts = {
        "recession": 16,
        "credit tightening": 11,
        "high interest": 9,
        "rate hike": 9,
        "default": 12,
        "demand slowdown": 8,
        "inflation": 5,
        "uncertainty": 6,
    }
    for phrase, impact in keyword_impacts.items():
        if phrase in macro_text:
            macro_score += impact

    def _clean_snippet(text: str, max_len: int = 320) -> str:
        clipped = " ".join(str(text or "").split())
        return clipped[:max_len].strip()

    qual_snippets = [_clean_snippet(s, 320) for s in qual_result.snippets if str(s).strip()]
    qual_snippets = [s for s in qual_snippets if len(s) >= 40][:8]

    return {
        "macro_stress_score": max(0.0, min(100.0, macro_score)),
        "macro_notes": [macro_result.answer] + macro_result.snippets[:3],
        "qual_snippets": qual_snippets,
        "sources": list(dict.fromkeys(macro_result.sources + qual_result.sources + strategy_result.sources + failure_result.sources)),
        "strategy_notes": [strategy_result.answer] if strategy_result.answer else [],
        "failure_check": {
            "answer": failure_result.answer,
            "snippets": failure_result.snippets,
            "sources": failure_result.sources,
        },
    }


def _collect_peer_metrics(peer_tickers: List[str], macro_stress_score: float) -> List[Dict[str, object]]:
    rows: List[Dict[str, object]] = []
    for ticker in peer_tickers:
        info = fetch_company_info(ticker)
        metrics = compute_metrics(fetch_financials(ticker), company_info=info)
        metrics, estimated = _impute_survivor_defaults(metrics, ticker)
        score, _ = MultiFactorRiskEngine(metrics, macro_stress_score).compute_score()
        rows.append({"ticker": ticker, "metrics": metrics, "risk_score": score, "estimated": estimated})
    return rows


def _layer_signals(layers: Dict[str, Dict[str, object]]) -> Dict[str, List[str]]:
    return {
        "macro": list(layers.get("macro", {}).get("signals", [])),
        "business_model": list(layers.get("business_model", {}).get("signals", [])),
        "financial_health": list(layers.get("financial_health", {}).get("signals", [])),
        "operational": list(layers.get("operational", {}).get("signals", [])),
        "qualitative": list(layers.get("qualitative", {}).get("signals", [])),
    }


def _chart_metric_gaps(metric_gaps: Dict[str, object]) -> alt.Chart:
    rows = []
    for k, v in metric_gaps.items():
        raw_gap = float(v or 0.0)
        scaled_gap = 0.0
        if raw_gap != 0:
            sign = 1.0 if raw_gap > 0 else -1.0
            scaled_gap = sign * (abs(raw_gap) ** 0.35)
        rows.append(
            {
                "Metric": _friendly_metric_name(k.replace("_gap", "")),
                "Scaled Gap": scaled_gap,
                "Raw Gap": raw_gap,
            }
        )
    df = pd.DataFrame(rows)
    return (
        alt.Chart(df)
        .mark_bar(cornerRadiusTopLeft=5, cornerRadiusTopRight=5)
        .encode(
            x=alt.X(
                "Metric:N",
                sort=None,
                title=None,
                axis=alt.Axis(labelAngle=-18, labelColor="#0f172a", labelLimit=180, labelPadding=8),
            ),
            y=alt.Y("Scaled Gap:Q", title="Relative Gap (scaled for readability)"),
            color=alt.condition(alt.datum["Scaled Gap"] >= 0, alt.value("#fb8500"), alt.value("#0ea5a6")),
            tooltip=["Metric", alt.Tooltip("Raw Gap:Q", format=",.3f"), alt.Tooltip("Scaled Gap:Q", format=",.3f")],
        )
        .properties(height=260)
        .configure_view(strokeOpacity=0)
        .configure_axis(
            labelColor="#0f172a",
            titleColor="#0f172a",
            labelFontSize=13,
            titleFontSize=13,
            gridColor="#cbd5e1",
        )
        .configure_axisX(labelAngle=-18, labelColor="#0f172a", titleColor="#0f172a", labelPadding=8)
        .configure_axisY(labelColor="#0f172a", titleColor="#0f172a")
        .configure_legend(labelColor="#0f172a", titleColor="#0f172a")
        .configure(background="#ffffff")
    )


def _chart_nlp_theme_scores(qual: Dict[str, object]) -> alt.Chart:
    theme_scores = dict(qual.get("theme_scores", {}) or {})
    theme_counts = dict(qual.get("themes", {}) or {})
    rows = []
    for theme, score in theme_scores.items():
        rows.append(
            {
                "Theme": _friendly_theme_name(theme),
                "Score": float(score),
                "Mentions": int(theme_counts.get(theme, 0) or 0),
            }
        )
    if not rows:
        rows = [{"Theme": "No Theme Signals", "Score": 0.0, "Mentions": 0}]
    df = pd.DataFrame(rows)
    return (
        alt.Chart(df)
        .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6)
        .encode(
            x=alt.X("Theme:N", sort="-y", title=None),
            y=alt.Y("Score:Q", title="Theme Severity Score (0-1)"),
            color=alt.condition(alt.datum.Score >= 0.45, alt.value("#e63946"), alt.value("#1d8a9e")),
            tooltip=["Theme", alt.Tooltip("Score:Q", format=".3f"), "Mentions"],
        )
        .properties(height=240)
        .configure_view(strokeOpacity=0)
        .configure_axis(
            labelColor="#0f172a",
            titleColor="#0f172a",
            labelFontSize=12,
            titleFontSize=12,
            gridColor="#cbd5e1",
        )
        .configure_axisX(labelAngle=-18, labelColor="#0f172a", titleColor="#0f172a")
        .configure_axisY(labelColor="#0f172a", titleColor="#0f172a")
        .configure(background="#ffffff")
    )


def _chart_before_after(original: float, adjusted: float) -> alt.Chart:
    df = pd.DataFrame(
        [
            {"Scenario": "Original", "Risk": float(original)},
            {"Scenario": "Counterfactual", "Risk": float(adjusted)},
        ]
    )
    return (
        alt.Chart(df)
        .mark_bar(cornerRadiusTopLeft=8, cornerRadiusTopRight=8)
        .encode(
            x=alt.X("Scenario:N", title=None, sort=["Original", "Counterfactual"]),
            y=alt.Y("Risk:Q", title="Risk Score"),
            color=alt.Color("Scenario:N", scale=alt.Scale(range=["#e63946", "#0ea5a6"]), legend=None),
            tooltip=["Scenario", "Risk"],
        )
        .properties(height=220)
        .configure_view(strokeOpacity=0)
        .configure_axis(
            labelColor="#0f172a",
            titleColor="#0f172a",
            labelFontSize=13,
            titleFontSize=13,
            gridColor="#cbd5e1",
        )
        .configure_axisX(labelAngle=0, labelColor="#0f172a", titleColor="#0f172a")
        .configure_axisY(labelColor="#0f172a", titleColor="#0f172a")
        .configure_legend(labelColor="#0f172a", titleColor="#0f172a")
        .configure(background="#ffffff")
    )


def _chart_risk_components(components: Dict[str, float]) -> alt.Chart:
    df = pd.DataFrame(
        [{"Component": k.replace("_", " ").title(), "Value": float(v)} for k, v in components.items()]
    )
    return (
        alt.Chart(df)
        .mark_arc(innerRadius=45)
        .encode(
            theta=alt.Theta(field="Value", type="quantitative"),
            color=alt.Color(
                field="Component",
                type="nominal",
                scale=alt.Scale(range=["#1d3557", "#0ea5a6", "#fb8500", "#8ecae6", "#457b9d"]),
                legend=alt.Legend(orient="right"),
            ),
            tooltip=["Component", "Value"],
        )
        .properties(height=280)
        .configure_view(strokeOpacity=0)
        .configure_title(color="#0f172a", fontSize=13)
        .configure_legend(
            labelColor="#0f172a",
            titleColor="#0f172a",
            labelFontSize=13,
            titleFontSize=13,
            symbolType="circle",
        )
        .configure(background="#ffffff")
    )


def _chart_component_delta(failing_components: Dict[str, float], survivor_components: Dict[str, float]) -> alt.Chart:
    rows = []
    for key, fail_val in failing_components.items():
        surv_val = float(survivor_components.get(key, 0.0))
        rows.append(
            {
                "Component": key.replace("_", " ").title(),
                "Delta": float(fail_val) - surv_val,
                "Failing": float(fail_val),
                "Survivor": surv_val,
            }
        )
    df = pd.DataFrame(rows)
    return (
        alt.Chart(df)
        .mark_bar(cornerRadiusTopLeft=6, cornerRadiusTopRight=6)
        .encode(
            x=alt.X("Component:N", title=None, sort=None),
            y=alt.Y("Delta:Q", title="Risk Delta (Failing - Survivor)"),
            color=alt.condition(alt.datum.Delta >= 0, alt.value("#e63946"), alt.value("#10b981")),
            tooltip=["Component", alt.Tooltip("Failing:Q", format=".3f"), alt.Tooltip("Survivor:Q", format=".3f"), "Delta"],
        )
        .properties(height=230)
        .configure_view(strokeOpacity=0)
        .configure_axis(labelColor="#0f172a", titleColor="#0f172a", labelFontSize=12, titleFontSize=12, gridColor="#cbd5e1")
        .configure(background="#ffffff")
    )


def _chart_peer_positioning(
    failing_ticker: str,
    failing_metrics: Dict[str, Optional[float]],
    failing_risk_score: float,
    survivor_rows: List[Dict[str, object]],
) -> alt.Chart:
    rows = []
    rows.append(
        {
            "Ticker": failing_ticker,
            "Current Ratio": float(failing_metrics.get("current_ratio") or 0.01),
            "Debt/Equity": float(failing_metrics.get("debt_to_equity") or 0.01),
            "Risk Score": float(failing_risk_score),
            "Group": "Failing",
        }
    )
    for row in survivor_rows:
        m = row.get("metrics", {})
        rows.append(
            {
                "Ticker": str(row.get("ticker")),
                "Current Ratio": float((m or {}).get("current_ratio") or 0.01),
                "Debt/Equity": float((m or {}).get("debt_to_equity") or 0.01),
                "Risk Score": float(row.get("risk_score") or 0.0),
                "Group": "Survivor",
            }
        )

    df = pd.DataFrame(rows)
    return (
        alt.Chart(df)
        .mark_circle(size=170, opacity=0.85)
        .encode(
            x=alt.X("Current Ratio:Q", title="Current Ratio (higher is better)"),
            y=alt.Y("Debt/Equity:Q", title="Debt/Equity (lower is better)"),
            color=alt.Color("Group:N", scale=alt.Scale(range=["#e63946", "#0ea5a6"])),
            size=alt.Size("Risk Score:Q", scale=alt.Scale(range=[80, 520])),
            tooltip=["Ticker", "Group", alt.Tooltip("Current Ratio:Q", format=".2f"), alt.Tooltip("Debt/Equity:Q", format=".2f"), "Risk Score"],
        )
        .properties(height=280)
        .configure_view(strokeOpacity=0)
        .configure_axis(labelColor="#0f172a", titleColor="#0f172a", labelFontSize=12, titleFontSize=12, gridColor="#cbd5e1")
        .configure_legend(labelColor="#0f172a", titleColor="#0f172a")
        .configure(background="#ffffff")
    )


def _glossary() -> Dict[str, str]:
    return {
        "Risk Score": "Composite 0-100 probability-like distress score built from debt, liquidity, growth, burn, and macro stress.",
        "Current Ratio": "Current assets divided by current liabilities. Below 1 generally means tighter liquidity.",
        "Debt/Equity": "Leverage ratio. Higher values indicate heavier debt burden relative to equity.",
        "Cash Burn": "Cash consumed by operations. Lower burn is healthier under stress.",
        "Counterfactual": "A simulated alternative world where the failing company adopts survivor-like metrics.",
        "Model Lab": "Local in-app analyst model used as a second opinion to stabilize reasoning output.",
    }


def _render_glossary_panel() -> None:
    glossary = _glossary()
    st.markdown("#### Hover Glossary")
    st.markdown(
        " ".join(
            [f"<span class='hint' title='{desc}'>{term}</span>" for term, desc in glossary.items()]
        ),
        unsafe_allow_html=True,
    )


def _chat_bubble(text: str, role: str) -> str:
    safe = html.escape(text or "")
    if role == "assistant":
        return (
            "<div style='background:#1f2937;border:1px solid #334155;border-radius:14px;"
            "padding:.62rem .72rem;color:#e2e8f0;font-size:.95rem;line-height:1.45;'>"
            f"{safe}</div>"
        )
    return (
        "<div style='background:#0b5d66;border:1px solid #14b8a6;border-radius:14px;padding:.55rem .65rem;"
        "color:#ecfeff;font-size:.92rem;line-height:1.42;text-align:right;'>"
        f"{safe}</div>"
    )

def _strengthen_reasoning(
    reasoning: Dict[str, object],
    *,
    deterministic_recommendations: List[str],
    layers: Dict[str, Dict[str, object]],
) -> Dict[str, object]:
    out = dict(reasoning)

    failure_drivers = list(out.get("failure_drivers", []) or [])
    if len(failure_drivers) < 3:
        layer_backfill: List[str] = []
        for key in ["financial_health", "operational", "business_model", "qualitative", "macro"]:
            layer_backfill.extend(list(layers.get(key, {}).get("signals", [])))
        for signal in layer_backfill:
            if signal not in failure_drivers:
                failure_drivers.append(signal)
            if len(failure_drivers) >= 3:
                break
    out["failure_drivers"] = failure_drivers[:3]

    measures = list(out.get("prevention_measures", []) or [])
    for rec in deterministic_recommendations:
        if rec not in measures:
            measures.append(rec)
        if len(measures) >= 4:
            break
    out["prevention_measures"] = measures[:4]

    if not str(out.get("plain_english_explainer", "")).strip():
        out["plain_english_explainer"] = (
            "This company failed because debt and cash pressure stayed high while revenue momentum weakened. "
            "The benchmark survivors kept stronger liquidity and lower leverage."
        )

    if not str(out.get("executive_summary", "")).strip():
        out["executive_summary"] = (
            "Consensus view: distress risk is materially reducible by applying survivor-like balance sheet and liquidity discipline."
        )

    return out


def _build_report_bundle(
    profile_name: str,
    ticker: str,
    failed: bool,
    reasoning: Dict[str, object],
    failing_risk_score: float,
    simulation: Dict[str, object],
    survivor_tickers: List[str],
    metric_gaps: Dict[str, object],
    qual_summary: Optional[Dict[str, Any]] = None,
) -> Tuple[str, str]:
    payload = {
        "generated_at": datetime.utcnow().isoformat() + "Z",
        "company": {"name": profile_name, "ticker": ticker, "failed": failed},
        "summary": reasoning,
        "scores": {
            "failing_risk_score": failing_risk_score,
            "adjusted_risk_score": simulation.get("adjusted_score"),
            "improvement_percentage": simulation.get("improvement_percentage"),
        },
        "survivor_cohort": survivor_tickers,
        "metric_gaps": metric_gaps,
        "qualitative_forensics": {
            "distress_intensity": (qual_summary or {}).get("distress_intensity"),
            "confidence": (qual_summary or {}).get("confidence"),
            "forensic_summary": (qual_summary or {}).get("forensic_summary"),
            "theme_scores": (qual_summary or {}).get("theme_scores", {}),
            "theme_mentions": (qual_summary or {}).get("themes", {}),
            "keywords": (qual_summary or {}).get("keywords", [])[:15],
        },
    }
    json_text = json.dumps(payload, indent=2)

    md = [
        f"# SignalForge Report: {profile_name} ({ticker})",
        "",
        f"- Failed case verified: **{failed}**",
        f"- Risk score: **{failing_risk_score:.2f}/100**",
        f"- Counterfactual adjusted risk: **{float(simulation.get('adjusted_score', 0)):.2f}/100**",
        f"- Improvement: **{float(simulation.get('improvement_percentage', 0)):.2f}%**",
        "",
        "## Plain-English Summary",
        str(reasoning.get("plain_english_explainer", "")),
        "",
        "## Why It Failed",
    ]
    for item in reasoning.get("failure_drivers", [])[:3]:
        md.append(f"- {item}")
    md.extend(["", "## What Survivors Did Differently"])
    for item in reasoning.get("survivor_differences", [])[:3]:
        md.append(f"- {item}")
    md.extend(["", "## Prevention Moves"])
    for item in reasoning.get("prevention_measures", [])[:3]:
        md.append(f"- {item}")
    md.extend(
        [
            "",
            "## NLP Forensics",
            f"- Distress intensity: **{float((qual_summary or {}).get('distress_intensity', 0.0)):.2f}/10**",
            f"- NLP confidence: **{float((qual_summary or {}).get('confidence', 0.0))*100:.1f}%**",
            f"- Summary: {(qual_summary or {}).get('forensic_summary', 'No qualitative summary available.')}",
        ]
    )
    markdown_text = "\n".join(md)

    return json_text, markdown_text


def _qa_context_from_report(
    *,
    profile_name: str,
    ticker: str,
    industry: str,
    reasoning: Dict[str, object],
    failing_risk_score: float,
    macro_stress_score: float,
    comparison: Dict[str, object],
    simulation: Dict[str, object],
    failing_metrics: Dict[str, Optional[float]],
    survivor_tickers: List[str],
    layers: Dict[str, Dict[str, object]],
    local_before_prob: float,
    local_after_prob: float,
    qual_summary: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    key_metrics = ["debt_to_equity", "current_ratio", "cash_burn", "revenue_growth", "revenue"]
    fail_core = {k: failing_metrics.get(k) for k in key_metrics}
    surv_avg = comparison.get("survivor_average_metrics", {}) or {}
    surv_core = {k: surv_avg.get(k) for k in key_metrics}

    return {
        "company": {"name": profile_name, "ticker": ticker, "industry": industry},
        "simple_view": {
            "plain_english_explainer": reasoning.get("plain_english_explainer"),
            "failure_drivers": reasoning.get("failure_drivers", []),
            "survivor_differences": reasoning.get("survivor_differences", []),
            "prevention_measures": reasoning.get("prevention_measures", []),
            "risk_scores": {
                "failing_risk": failing_risk_score,
                "macro_stress": macro_stress_score,
                "adjusted_risk": simulation.get("adjusted_score"),
                "improvement_pct": simulation.get("improvement_percentage"),
            },
        },
        "analyst_view": {
            "survivor_cohort": survivor_tickers,
            "failing_core_metrics": fail_core,
            "survivor_core_metrics": surv_core,
            "metric_gaps": comparison.get("metric_gaps", {}),
            "component_scores": comparison.get("failing_components", {}),
            "layer_signals": {
                "macro": list(layers.get("macro", {}).get("signals", [])),
                "business_model": list(layers.get("business_model", {}).get("signals", [])),
                "financial_health": list(layers.get("financial_health", {}).get("signals", [])),
                "operational": list(layers.get("operational", {}).get("signals", [])),
                "qualitative": list(layers.get("qualitative", {}).get("signals", [])),
            },
            "local_model_probabilities": {
                "before": local_before_prob,
                "after": local_after_prob,
            },
            "qualitative_forensics": {
                "distress_intensity": (qual_summary or {}).get("distress_intensity"),
                "confidence": (qual_summary or {}).get("confidence"),
                "forensic_summary": (qual_summary or {}).get("forensic_summary"),
                "theme_scores": (qual_summary or {}).get("theme_scores", {}),
                "theme_mentions": (qual_summary or {}).get("themes", {}),
                "top_keywords": (qual_summary or {}).get("keywords", [])[:10],
            },
        },
    }


@st.cache_resource
def _local_model() -> LocalAnalystModel:
    model = LocalAnalystModel(random_state=42)
    model.train(n_samples=7000)
    return model


def main() -> None:
    st.set_page_config(page_title="SignalForge", page_icon="ðŸ“‰", layout="wide")
    _inject_styles()
    _render_header()

    if "analysis_active" not in st.session_state:
        st.session_state["analysis_active"] = False
    if "assistant_open" not in st.session_state:
        st.session_state["assistant_open"] = False
    if "assistant_messages" not in st.session_state:
        st.session_state["assistant_messages"] = [
            {
                "role": "assistant",
                "text": "I will be your personal AI for this SignalForge Failure Intelligence report.",
            }
        ]
    if "assistant_pending_question" not in st.session_state:
        st.session_state["assistant_pending_question"] = None
    if "assistant_waiting" not in st.session_state:
        st.session_state["assistant_waiting"] = False
    if "analysis_cache" not in st.session_state:
        st.session_state["analysis_cache"] = None

    tavily_key = os.getenv("TAVILY_API_KEY", "")
    groq_key = os.getenv("GROQ_API_KEY", "")

    with st.container(border=True):
        st.markdown("### Start Analysis")
        st.write("Enter a company full name or ticker symbol.")
        company_input = st.text_input("Company Name or Ticker", value="", placeholder="Example: Lehman Brothers or LEHMQ")

        with st.expander("Advanced Controls", expanded=False):
            col_a, col_b = st.columns(2)
            with col_a:
                max_auto_peers = st.slider("Peer candidate count", 4, 10, 6)
            with col_b:
                survivor_count = st.slider("Survivor benchmark size", 2, 5, 3)
            st.caption("Keys are loaded from `.env` automatically.")

        run_clicked = st.button("Run Failure Forensics", type="primary", use_container_width=True)

    if run_clicked:
        st.session_state["analysis_active"] = True
        st.session_state["analysis_cache"] = None
        st.session_state["assistant_messages"] = [
            {
                "role": "assistant",
                "text": "I will be your personal AI for this SignalForge Failure Intelligence report.",
            }
        ]
        st.session_state["assistant_pending_question"] = None
        st.session_state["assistant_waiting"] = False

    if not st.session_state.get("analysis_active", False):
        return

    if not company_input.strip():
        st.error("Please enter a company name or ticker.")
        st.session_state["analysis_active"] = False
        return

    tavily = TavilyClient(tavily_key)
    groq = GroqReasoningClient(groq_key)
    local_model = _local_model()
    cache_key = {
        "company_input": company_input.strip().upper(),
        "max_auto_peers": max_auto_peers,
        "survivor_count": survivor_count,
    }
    cached = st.session_state.get("analysis_cache")
    use_cache = bool(cached) and cached.get("cache_key") == cache_key and not run_clicked

    if use_cache:
        bundle = cached["bundle"]
        profile = bundle["profile"]
        intelligence = bundle["intelligence"]
        failure_status = bundle["failure_status"]
        failed = bundle["failed"]
        failing_metrics = bundle["failing_metrics"]
        used_failed_imputation = bundle["used_failed_imputation"]
        macro_stress_score = bundle["macro_stress_score"]
        layers = bundle["layers"]
        failing_risk_score = bundle["failing_risk_score"]
        failing_components = bundle["failing_components"]
        survivor_rows = bundle["survivor_rows"]
        survivor_tickers = bundle["survivor_tickers"]
        comparison = bundle["comparison"]
        simulation = bundle["simulation"]
        recommendations = bundle["recommendations"]
        reasoning = bundle["reasoning"]
        qual = bundle.get("qual") or qualitative_summary("", intelligence.get("qual_snippets", []))
        local_before = bundle["local_before"]
        local_after = bundle["local_after"]
    else:
        with st.spinner("Resolving company and verifying failure status..."):
            resolved = resolve_company_input(company_input)
            if resolved is None:
                st.error("Could not resolve that company input.")
                st.session_state["analysis_active"] = False
                return

            profile = fetch_company_profile(resolved.ticker)
            info = fetch_company_info(profile.ticker)
            intelligence = _fetch_tavily_intelligence(tavily, profile.name, profile.ticker, profile.industry)

            failure_status = groq.verify_failure_status(
                company_input=company_input,
                resolved_name=profile.name,
                ticker=profile.ticker,
                tavily_answer=str(intelligence["failure_check"]["answer"]),
                tavily_snippets=list(intelligence["failure_check"]["snippets"]),
            )

        failed = bool(failure_status.get("is_failed", False))
        if not failed:
            st.markdown("### Verification")
            v1, v2, v3 = st.columns([1.6, 1, 1])
            v1.write(f"Resolved: **{profile.name} ({profile.ticker})**")
            v2.metric("Failure Confidence", f"{float(failure_status.get('confidence', 0.0))*100:.1f}%")
            v3.write(f"Model: `{failure_status.get('model_used', 'fallback')}`")
            st.markdown('<span class="badge badge-ok">Likely Not Failed</span>', unsafe_allow_html=True)
            st.warning("This case does not appear to be failed/distressed. Enter a failed company to generate a full forensic report.")
            st.session_state["analysis_active"] = False
            return

        progress = st.progress(0, text="Collecting financial and peer data...")
        failing_metrics = compute_metrics(fetch_financials(profile.ticker), company_info=info)
        if _core_metric_quality(failing_metrics) < 2:
            failing_metrics, used_failed_imputation = _impute_failed_defaults(failing_metrics)
        else:
            used_failed_imputation = False

        qual = qualitative_summary("", intelligence["qual_snippets"])
        raw_qual_intensity = float(qual.get("distress_intensity", sum(qual["themes"].values())))
        qualitative_intensity = max(0.0, min(6.0, raw_qual_intensity * 0.62))
        macro_stress_score = float(intelligence["macro_stress_score"])

        layer_engine = LayeredAnalysisEngine(failing_metrics, qual["themes"], macro_stress_score)
        layers = layer_engine.analyze_all_layers()
        failing_risk_score, failing_components = MultiFactorRiskEngine(failing_metrics, macro_stress_score).compute_score()

        progress.progress(40, text="Building survivor benchmark...")
        peers = find_peer_companies(profile.ticker, max_peers=max_auto_peers)
        peer_rows = _collect_peer_metrics([p["ticker"] for p in peers["peers"]], macro_stress_score)
        if not peer_rows:
            st.error("Unable to collect peer data.")
            return

        better = sorted([x for x in peer_rows if x["risk_score"] < failing_risk_score], key=lambda x: x["risk_score"])
        survivor_rows = better[:survivor_count] if better else sorted(peer_rows, key=lambda x: x["risk_score"])[:survivor_count]

        survivor_tickers = [x["ticker"] for x in survivor_rows]
        survivor_metrics = [x["metrics"] for x in survivor_rows]

        comparison = compare_failure_vs_survivors(failing_metrics, survivor_metrics, macro_stress_score)
        simulation = simulate_counterfactual(failing_metrics, comparison["survivor_average_metrics"], macro_stress_score)
        recommendations = generate_strategy_recommendations(failing_metrics, comparison["survivor_average_metrics"])

        progress.progress(74, text="Running Groq and local analyst reasoning...")
        reasoning = groq.generate_reasoning(
            company_name=profile.name,
            ticker=profile.ticker,
            industry=profile.industry,
            failing_risk_score=failing_risk_score,
            survivor_tickers=survivor_tickers,
            layer_signals={
                "macro": list(layers.get("macro", {}).get("signals", [])),
                "business_model": list(layers.get("business_model", {}).get("signals", [])),
                "financial_health": list(layers.get("financial_health", {}).get("signals", [])),
                "operational": list(layers.get("operational", {}).get("signals", [])),
                "qualitative": list(layers.get("qualitative", {}).get("signals", [])),
            },
            metric_gaps=comparison["metric_gaps"],
            simulation=simulation,
            recommendations=recommendations,
            tavily_notes=intelligence["macro_notes"] + intelligence["strategy_notes"],
        )

        local_before = local_model.predict(failing_metrics, macro_stress_score, qualitative_intensity)
        local_after = local_model.predict(simulation["adjusted_metrics"], macro_stress_score, qualitative_intensity)
        reasoning = _strengthen_reasoning(
            reasoning,
            deterministic_recommendations=recommendations,
            layers=layers,
        )

        technical_notes = list(reasoning.get("technical_notes", []) or [])
        technical_notes.insert(
            0,
            (
                f"Local model distress probability changes from {local_before.risk_probability*100:.1f}% "
                f"to {local_after.risk_probability*100:.1f}% under the counterfactual."
            ),
        )
        reasoning["technical_notes"] = technical_notes[:4]
        progress.progress(100, text="Report ready.")

        st.session_state["analysis_cache"] = {
            "cache_key": cache_key,
            "bundle": {
                "profile": profile,
                "intelligence": intelligence,
                "failure_status": failure_status,
                "failed": failed,
                "failing_metrics": failing_metrics,
                "used_failed_imputation": used_failed_imputation,
                "macro_stress_score": macro_stress_score,
                "layers": layers,
                "failing_risk_score": failing_risk_score,
                "failing_components": failing_components,
                "survivor_rows": survivor_rows,
                "survivor_tickers": survivor_tickers,
                "comparison": comparison,
                "simulation": simulation,
                "recommendations": recommendations,
                "reasoning": reasoning,
                "qual": qual,
                "local_before": local_before,
                "local_after": local_after,
            },
        }

    st.markdown("### Verification")
    v1, v2, v3 = st.columns([1.6, 1, 1])
    v1.write(f"Resolved: **{profile.name} ({profile.ticker})**")
    v2.metric("Failure Confidence", f"{float(failure_status.get('confidence', 0.0))*100:.1f}%")
    v3.write(f"Model: `{failure_status.get('model_used', 'fallback')}`")

    failed = bool(failure_status.get("is_failed", False))
    if failed:
        st.markdown('<span class="badge badge-failed">Failed/Distressed Case Confirmed</span>', unsafe_allow_html=True)
    else:
        st.markdown('<span class="badge badge-ok">Likely Not Failed</span>', unsafe_allow_html=True)

    st.write(str(failure_status.get("reason", "")))
    for e in failure_status.get("evidence", [])[:3]:
        st.write(f"- {e}")

    if not failed:
        st.warning("This case does not appear to be failed/distressed. Enter a failed company to generate a full forensic report.")
        st.session_state["analysis_active"] = False
        return

    report_json, report_md = _build_report_bundle(
        profile.name,
        profile.ticker,
        failed,
        reasoning,
        failing_risk_score,
        simulation,
        survivor_tickers,
        comparison["metric_gaps"],
        qual,
    )

    st.markdown("---")
    st.markdown("## Report")

    e1, e2 = st.columns(2)
    with e1:
        st.download_button(
            "Export JSON Report",
            data=report_json,
            file_name=f"signalforge_{profile.ticker.lower()}_report.json",
            mime="application/json",
            use_container_width=True,
        )
    with e2:
        st.download_button(
            "Export Markdown Report",
            data=report_md,
            file_name=f"signalforge_{profile.ticker.lower()}_report.md",
            mime="text/markdown",
            use_container_width=True,
        )

    tabs = st.tabs(["Simple View", "Analyst View", "Scenario Lab", "Model Lab", "Evidence"])

    with tabs[0]:
        st.markdown("### Plain-English Story")
        st.markdown(
            "<div class='wow'><b>Judge Highlight:</b> This engine combines forensic reconstruction, survivor benchmarking, and "
            "counterfactual simulation in one flow.</div>",
            unsafe_allow_html=True,
        )
        st.markdown(
            f"<div class='explain'>{reasoning.get('plain_english_explainer', 'No plain-English summary available.')}</div>",
            unsafe_allow_html=True,
        )

        s1, s2, s3, s4 = st.columns(4)
        s1.metric("Failure Risk", f"{failing_risk_score:.2f}/100")
        s2.metric("Adjusted Risk", f"{float(simulation['adjusted_score']):.2f}/100")
        s3.metric("Risk Improvement", f"{float(simulation['improvement_percentage']):.2f}%")
        s4.metric("Local Analyst", f"{local_before.risk_probability*100:.1f}%")
        st.caption(
            f"NLP distress intensity: {float(qual.get('distress_intensity', 0.0)):.1f}/10 "
            f"(confidence {float(qual.get('confidence', 0.0))*100:.0f}%)."
        )

        c_left, c_right = st.columns(2)
        with c_left:
            st.altair_chart(_chart_before_after(failing_risk_score, float(simulation["adjusted_score"])), use_container_width=True)
        with c_right:
            st.altair_chart(_chart_metric_gaps(comparison["metric_gaps"]), use_container_width=True)

        _render_glossary_panel()

        st.markdown("#### Why It Failed")
        for item in reasoning.get("failure_drivers", [])[:3]:
            st.write(f"- {item}")

        st.markdown("#### How It Could Have Been Prevented")
        for item in reasoning.get("prevention_measures", [])[:3]:
            st.write(f"- {item}")

    with tabs[1]:
        a1, a2, a3, a4 = st.columns(4)
        a1.metric("Risk Score", f"{failing_risk_score:.2f}")
        a2.metric("Survivor Avg", f"{float(comparison['survivor_score']):.2f}")
        a3.metric("Macro Stress", f"{macro_stress_score:.1f}")
        a4.metric("Local Post-Fix", f"{local_after.risk_probability*100:.1f}%")

        st.markdown(f"**Survivor Cohort:** {', '.join(survivor_tickers)}")

        st.markdown("#### Core Metrics")
        t1, t2 = st.columns(2)
        fail_table = _metrics_table(_clean_metrics(failing_metrics), hide_missing=True)
        survivor_table = _metrics_table(_clean_metrics(comparison["survivor_average_metrics"]), hide_missing=True)
        with t1:
            st.write("Failing Company")
            if fail_table.empty:
                st.warning("No concrete failing-company metrics available for this symbol.")
            else:
                st.dataframe(fail_table, use_container_width=True)
        with t2:
            st.write("Survivor Average")
            if survivor_table.empty:
                st.warning("No survivor metrics available.")
            else:
                st.dataframe(survivor_table, use_container_width=True)

        st.markdown("#### Risk Component Mix")
        st.altair_chart(_chart_risk_components(failing_components), use_container_width=True)

        st.markdown("#### Component Delta vs Survivors")
        st.altair_chart(
            _chart_component_delta(
                comparison.get("failing_components", {}),
                comparison.get("survivor_components", {}),
            ),
            use_container_width=True,
        )

        st.markdown("#### Peer Positioning Map")
        st.altair_chart(
            _chart_peer_positioning(profile.ticker, failing_metrics, failing_risk_score, survivor_rows),
            use_container_width=True,
        )

        st.markdown("#### NLP Distress Forensics")
        q1, q2, q3 = st.columns(3)
        q1.metric("Distress Intensity", f"{float(qual.get('distress_intensity', 0.0)):.2f}/10")
        q2.metric("NLP Confidence", f"{float(qual.get('confidence', 0.0))*100:.1f}%")
        q3.metric("Positive vs Negated", f"{int(qual.get('positive_mentions', 0))} / {int(qual.get('negated_total', 0))}")

        st.altair_chart(_chart_nlp_theme_scores(qual), use_container_width=True)
        kdf = pd.DataFrame({"Top Keywords": list(qual.get("keywords", []))[:15]})
        if not kdf.empty:
            st.dataframe(kdf, use_container_width=True)
        st.write(str(qual.get("forensic_summary", "")))

        st.markdown("#### Layered Signals")
        lcols = st.columns(5)
        names = ["macro", "business_model", "financial_health", "operational", "qualitative"]
        titles = ["Macro", "Business", "Financial", "Operational", "Qualitative"]
        for i, key in enumerate(names):
            lcols[i].markdown(f"**{titles[i]}**")
            signals = list(layers.get(key, {}).get("signals", []))
            if not signals:
                lcols[i].write("- No strong signal")
            else:
                for s in signals[:3]:
                    lcols[i].write(f"- {s}")

        if used_failed_imputation:
            st.info("Some failed-company metrics were estimated due limited filing availability for this symbol.")

    with tabs[2]:
        st.markdown("### Interactive Scenario Lab")
        st.caption("Adjust strategic levers and instantly see simulated risk impact. Hover each control for meaning.")

        s_col1, s_col2 = st.columns(2)
        with s_col1:
            dte = st.slider(
                "Debt / Equity",
                min_value=0.2,
                max_value=6.0,
                value=float(failing_metrics.get("debt_to_equity") or 3.1),
                step=0.05,
                help="Lower debt/equity usually reduces distress risk.",
            )
            cr = st.slider(
                "Current Ratio",
                min_value=0.3,
                max_value=3.0,
                value=float(failing_metrics.get("current_ratio") or 0.8),
                step=0.05,
                help="Higher current ratio indicates stronger short-term liquidity.",
            )
        with s_col2:
            burn_m = st.slider(
                "Annual Cash Burn ($M)",
                min_value=0,
                max_value=500,
                value=int((failing_metrics.get("cash_burn") or 250_000_000.0) / 1_000_000),
                step=5,
                help="Lower cash burn generally improves resilience.",
            )
            rev_growth = st.slider(
                "Revenue Growth",
                min_value=-0.5,
                max_value=0.4,
                value=float(failing_metrics.get("revenue_growth") or -0.1),
                step=0.01,
                help="Higher growth improves demand-side resilience.",
            )

        custom_metrics = dict(failing_metrics)
        custom_metrics["debt_to_equity"] = dte
        custom_metrics["current_ratio"] = cr
        custom_metrics["cash_burn"] = float(burn_m) * 1_000_000.0
        custom_metrics["revenue_growth"] = rev_growth
        if custom_metrics.get("revenue") is None:
            custom_metrics["revenue"] = 1_000_000_000.0

        custom_score, _ = MultiFactorRiskEngine(custom_metrics, macro_stress_score).compute_score()
        custom_improvement = ((failing_risk_score - custom_score) / max(failing_risk_score, 1e-6)) * 100

        c_metric1, c_metric2, c_metric3 = st.columns(3)
        c_metric1.metric("Original Risk", f"{failing_risk_score:.2f}")
        c_metric2.metric("Scenario Risk", f"{custom_score:.2f}")
        c_metric3.metric("Scenario Improvement", f"{custom_improvement:.2f}%")
        st.altair_chart(_chart_before_after(failing_risk_score, custom_score), use_container_width=True)

    with tabs[3]:
        st.markdown("### Local Analyst Model (Trained In-App)")
        st.info(
            "What this tab does: it runs a local in-app analyst model that estimates distress probability from financial + macro signals. "
            "It is used as a second opinion beside Groq so reasoning is more stable and auditable."
        )
        st.write(
            "How to read it: higher probability means the company profile looks more distressed. "
            "Top Local Drivers tell you which factors are pushing risk up or down."
        )

        m1, m2 = st.columns(2)
        with m1:
            st.metric("Local Distress Probability", f"{local_before.risk_probability*100:.1f}%")
            st.write(f"Classification: **{local_before.label}**")
            st.markdown("Top Local Drivers:")
            for d in local_before.top_drivers:
                st.write(f"- {d}")
        with m2:
            features_df = pd.DataFrame(
                [{"Feature": k.replace("_", " ").title(), "Value": v} for k, v in local_before.feature_values.items()]
            )
            st.dataframe(features_df, use_container_width=True)

        if reasoning.get("technical_notes"):
            st.markdown("Groq Technical Notes:")
            for note in reasoning.get("technical_notes", [])[:3]:
                st.write(f"- {note}")

    with tabs[4]:
        st.markdown("### Failure Verification Evidence")
        st.write(str(intelligence["failure_check"]["answer"]))
        for line in intelligence["failure_check"]["snippets"][:6]:
            st.write(f"- {line}")

        st.markdown("### NLP Evidence Digest")
        st.write(str(qual.get("forensic_summary", "")))

        theme_evidence = dict(qual.get("theme_evidence", {}) or {})
        shown_theme = False
        for theme, snippets in theme_evidence.items():
            if not snippets:
                continue
            shown_theme = True
            st.markdown(f"**{_friendly_theme_name(theme)}**")
            for item in snippets[:2]:
                st.write(f"- {item}")
        if not shown_theme:
            st.write("No high-confidence qualitative evidence snippets found.")

        st.markdown("### Tavily Strategy Notes")
        if intelligence["strategy_notes"]:
            for note in intelligence["strategy_notes"]:
                st.write(f"- {note}")
        else:
            st.write("No strategy notes returned.")

        st.markdown("### Source Trace")
        if intelligence["sources"]:
            for url in intelligence["sources"]:
                st.write(f"- {url}")

    qa_context = _qa_context_from_report(
        profile_name=profile.name,
        ticker=profile.ticker,
        industry=profile.industry,
        reasoning=reasoning,
        failing_risk_score=failing_risk_score,
        macro_stress_score=macro_stress_score,
        comparison=comparison,
        simulation=simulation,
        failing_metrics=failing_metrics,
        survivor_tickers=survivor_tickers,
        layers=layers,
        local_before_prob=local_before.risk_probability,
        local_after_prob=local_after.risk_probability,
        qual_summary=qual,
    )

    if not st.session_state.get("assistant_open", False):
        with st.container(key="jarvis_trigger"):
            if st.button("ðŸ’¬ Ask Me", key="jarvis_open_btn", use_container_width=True):
                st.session_state["assistant_open"] = True
                st.rerun()
    else:
        with st.container(key="jarvis_panel"):
            hdr_left, hdr_right = st.columns([4.8, 1.2])
            hdr_left.markdown("<div class='jarvis-title'>SignalForge AI</div>", unsafe_allow_html=True)
            hdr_left.markdown("<div class='jarvis-sub'>Personal AI for this report</div>", unsafe_allow_html=True)
            if hdr_right.button("âœ•", key="jarvis_close_btn", type="secondary", use_container_width=True):
                st.session_state["assistant_open"] = False
                st.rerun()

            for msg in st.session_state.get("assistant_messages", [])[-8:]:
                st.markdown(_chat_bubble(str(msg.get("text", "")), str(msg.get("role", "assistant"))), unsafe_allow_html=True)

            with st.form("jarvis_form", clear_on_submit=False):
                ask_q = st.text_input(
                    "Ask about this report...",
                    value=st.session_state.get("jarvis_q", ""),
                    key="jarvis_q",
                    label_visibility="collapsed",
                    placeholder="Ask about this report...",
                )
                send_now = st.form_submit_button(
                    "Ask Me",
                    type="primary",
                    use_container_width=True,
                    disabled=bool(st.session_state.get("assistant_waiting", False)),
                )

            if send_now and ask_q.strip() and not st.session_state.get("assistant_waiting", False):
                q = ask_q.strip()
                st.session_state["assistant_messages"].append({"role": "user", "text": q})
                st.session_state["assistant_messages"].append({"role": "assistant", "text": "Typing..."})
                st.session_state["assistant_pending_question"] = q
                st.session_state["assistant_waiting"] = True
                st.session_state["jarvis_q"] = ""
                st.rerun()

            pending_q = st.session_state.get("assistant_pending_question")
            if st.session_state.get("assistant_waiting", False) and pending_q:
                with st.spinner("SignalForge AI is analyzing..."):
                    try:
                        web_search_1 = tavily.search(
                            f"{profile.name} {profile.ticker} {pending_q}",
                            max_results=4,
                        )
                        web_search_2 = tavily.search(
                            f"{profile.industry} distressed company survivor strategies {pending_q}",
                            max_results=4,
                        )
                        web_evidence = []
                        for snippet, source in zip(web_search_1.snippets[:4], web_search_1.sources[:4]):
                            web_evidence.append({"snippet": snippet, "source": source})
                        for snippet, source in zip(web_search_2.snippets[:4], web_search_2.sources[:4]):
                            web_evidence.append({"snippet": snippet, "source": source})

                        answer = groq.answer_report_question(
                            question=pending_q,
                            report_context=qa_context,
                            web_evidence=web_evidence,
                        )
                        answer_text = str(answer.get("answer", "")).strip() or "I recommend starting with immediate liquidity stabilization."
                        rationale = str(answer.get("rationale", "")).strip()
                        if rationale:
                            answer_text = f"{answer_text}\n\nWhy: {rationale}"
                    except Exception:
                        answer_text = "I could not complete that request right now. Please try again."

                msgs = st.session_state.get("assistant_messages", [])
                if msgs and msgs[-1].get("role") == "assistant" and msgs[-1].get("text") == "Typing...":
                    msgs[-1] = {"role": "assistant", "text": answer_text}
                else:
                    msgs.append({"role": "assistant", "text": answer_text})
                st.session_state["assistant_messages"] = msgs
                st.session_state["assistant_pending_question"] = None
                st.session_state["assistant_waiting"] = False
                st.rerun()

    st.caption(f"Reasoning model: {reasoning.get('model_used', 'fallback')} | Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
